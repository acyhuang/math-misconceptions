{"cells":[{"cell_type":"markdown","metadata":{},"source":["# BERT"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:26.311732Z","iopub.status.busy":"2024-12-02T01:34:26.311395Z","iopub.status.idle":"2024-12-02T01:34:26.315531Z","shell.execute_reply":"2024-12-02T01:34:26.314667Z","shell.execute_reply.started":"2024-12-02T01:34:26.311668Z"},"trusted":true},"outputs":[],"source":["local = True\n","log = True\n","log_detail = False"]},{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:22.162885Z","iopub.status.busy":"2024-12-02T01:34:22.161893Z","iopub.status.idle":"2024-12-02T01:34:22.167444Z","shell.execute_reply":"2024-12-02T01:34:22.166513Z","shell.execute_reply.started":"2024-12-02T01:34:22.162850Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AdamW\n","from sklearn.preprocessing import LabelEncoder\n","\n","import os\n","import sys\n","sys.path.append(os.path.abspath('..'))\n","import pickle"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:26.184208Z","iopub.status.busy":"2024-12-02T01:34:26.183534Z","iopub.status.idle":"2024-12-02T01:34:26.188821Z","shell.execute_reply":"2024-12-02T01:34:26.187941Z","shell.execute_reply.started":"2024-12-02T01:34:26.184176Z"},"trusted":true},"outputs":[],"source":["pd.set_option('display.max_columns', None)\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.width', None)\n","pd.set_option('display.max_colwidth', None)"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:26.475728Z","iopub.status.busy":"2024-12-02T01:34:26.475428Z","iopub.status.idle":"2024-12-02T01:34:26.545321Z","shell.execute_reply":"2024-12-02T01:34:26.544572Z","shell.execute_reply.started":"2024-12-02T01:34:26.475700Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(1) Imported data\n"]}],"source":["if local:\n","    misconceptions = pd.read_csv('../kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv', index_col='MisconceptionId')\n","    train = pd.read_csv('../kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv')\n","    test = pd.read_csv('../kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv')\n","else:\n","    misconceptions = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/misconception_mapping.csv', index_col='MisconceptionId')\n","    train = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/train.csv')\n","    test = pd.read_csv('/kaggle/input/eedi-mining-misconceptions-in-mathematics/test.csv')\n","if log: print(\"(1) Imported data\")"]},{"cell_type":"markdown","metadata":{},"source":["## Clean data"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:26.749110Z","iopub.status.busy":"2024-12-02T01:34:26.748796Z","iopub.status.idle":"2024-12-02T01:34:26.812404Z","shell.execute_reply":"2024-12-02T01:34:26.811500Z","shell.execute_reply.started":"2024-12-02T01:34:26.749082Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(2) Created train_melted\n"]}],"source":["# Define the identifier columns\n","id_cols = [\n","    'QuestionId', 'ConstructId', 'ConstructName', \n","    'SubjectId', 'SubjectName', 'CorrectAnswer', 'QuestionText'\n","]\n","\n","# Define the corresponding Answer options\n","answer_cols = ['AnswerAText', 'AnswerBText', 'AnswerCText', 'AnswerDText']\n","misconception_cols = ['MisconceptionAId', 'MisconceptionBId', 'MisconceptionCId', 'MisconceptionDId']\n","\n","# Melt Answer Text\n","text_melted = train.melt(\n","    id_vars=id_cols,\n","    value_vars=answer_cols,\n","    var_name='Attribute',\n","    value_name='AnswerText'\n",")\n","\n","# Melt Misconception IDs\n","misconception_melted = train.melt(\n","    id_vars=id_cols,\n","    value_vars=misconception_cols,\n","    var_name='Attribute',\n","    value_name='MisconceptionId'\n",")\n","\n","# Extract the option letter (A, B, C, D) and the attribute type\n","text_melted['AnswerOption'] = text_melted['Attribute'].str.extract(r'Answer([ABCD])Text')[0]\n","misconception_melted['AnswerOption'] = misconception_melted['Attribute'].str.extract(r'Misconception([ABCD])Id')[0]\n","\n","# Drop the original 'Attribute' columns as they are no longer needed\n","text_melted.drop('Attribute', axis=1, inplace=True)\n","misconception_melted.drop('Attribute', axis=1, inplace=True)\n","\n","# Merge the two melted DataFrames on id_vars and AnswerOption\n","train_melted = pd.merge(\n","    text_melted,\n","    misconception_melted,\n","    on=id_cols + ['AnswerOption'],\n","    how='left'\n",")\n","\n","train_melted = train_melted.merge(misconceptions, left_on='MisconceptionId', right_index=True, how='left')\n","if log: print(\"(2) Created train_melted\")"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:27.179089Z","iopub.status.busy":"2024-12-02T01:34:27.178802Z","iopub.status.idle":"2024-12-02T01:34:27.183510Z","shell.execute_reply":"2024-12-02T01:34:27.182587Z","shell.execute_reply.started":"2024-12-02T01:34:27.179063Z"},"trusted":true},"outputs":[],"source":["misconception_list = list(misconceptions['MisconceptionName'])"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:27.506996Z","iopub.status.busy":"2024-12-02T01:34:27.506641Z","iopub.status.idle":"2024-12-02T01:34:27.564832Z","shell.execute_reply":"2024-12-02T01:34:27.564038Z","shell.execute_reply.started":"2024-12-02T01:34:27.506968Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(3) Shaped train_melted to (3623, 11)\n"]}],"source":["if log_detail: print(\"Shape before:\", train_melted.shape)\n","\n","# Remove rows with missing MisconceptionName, remove misconceptinos that only appear once\n","train_melted = train_melted.dropna(subset=['MisconceptionName'])\n","train_melted = train_melted.groupby('MisconceptionId').filter(lambda x: len(x) > 1)\n","\n","if log_detail: print(\"Shape after:\", train_melted.shape)\n","if log: print(\"(3) Shaped train_melted to\", train_melted.shape)"]},{"cell_type":"markdown","metadata":{},"source":["## Tokenize"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:27.700361Z","iopub.status.busy":"2024-12-02T01:34:27.699781Z","iopub.status.idle":"2024-12-02T01:34:27.718866Z","shell.execute_reply":"2024-12-02T01:34:27.717991Z","shell.execute_reply.started":"2024-12-02T01:34:27.700329Z"},"trusted":true},"outputs":[],"source":["# Split into training and validation sets\n","\n","train, valid = train_test_split(train_melted, test_size=0.25, random_state=123, stratify=train_melted['MisconceptionName'])"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:27.841147Z","iopub.status.busy":"2024-12-02T01:34:27.840213Z","iopub.status.idle":"2024-12-02T01:34:33.193417Z","shell.execute_reply":"2024-12-02T01:34:33.192294Z","shell.execute_reply.started":"2024-12-02T01:34:27.841114Z"},"trusted":true},"outputs":[],"source":["from transformers import BertTokenizer\n","\n","if local: \n","    bert_path = 'bert-base-uncased'\n","else:\n","    bert_path = '/kaggle/input/google-bertbert-base-uncased/transformers/default/1/cache/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594'\n","\n","tokenizer = BertTokenizer.from_pretrained(bert_path)\n","\n","def tokenize_data(question, answer, max_length=256):\n","    return tokenizer.encode_plus(\n","        question,\n","        answer,\n","        add_special_tokens=True,\n","        max_length=max_length,\n","        padding='max_length',\n","        truncation='only_first',\n","        return_attention_mask=True,\n","        return_tensors='pt'\n","    )"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:33.195913Z","iopub.status.busy":"2024-12-02T01:34:33.195345Z","iopub.status.idle":"2024-12-02T01:34:33.258572Z","shell.execute_reply":"2024-12-02T01:34:33.257629Z","shell.execute_reply.started":"2024-12-02T01:34:33.195874Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'input_ids': tensor([[ 101, 2054, 2003, 1996, 2675, 7117, 1997, 7032, 1029,  102, 1032, 1006,\n","         3590, 1032, 1007,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"]}],"source":["# Example tokenization\n","if local:\n","    tokenized_sample = tokenize_data(train['QuestionText'].iloc[0], train['AnswerText'].iloc[0])\n","    print(tokenized_sample)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:33.260026Z","iopub.status.busy":"2024-12-02T01:34:33.259711Z","iopub.status.idle":"2024-12-02T01:34:34.093903Z","shell.execute_reply":"2024-12-02T01:34:34.093065Z","shell.execute_reply.started":"2024-12-02T01:34:33.259994Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch import nn\n","from transformers import BertModel\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self, n_classes):\n","        super(BERTClassifier, self).__init__()\n","        if local:\n","            self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        else:\n","            self.bert = BertModel.from_pretrained('/kaggle/input/google-bertbert-base-uncased/transformers/default/1/cache/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594')\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","\n","    def forward(self, input_ids, attention_mask):\n","        outputs = self.bert(\n","            input_ids=input_ids,\n","            attention_mask=attention_mask\n","        )\n","\n","        pooled_output = outputs[1]  # [CLS] token\n","        output = self.dropout(pooled_output)\n","        return self.out(output)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# Encode labels\n","le = LabelEncoder()\n","train_labels = le.fit_transform(train['MisconceptionName'])\n","val_labels = le.transform(valid['MisconceptionName'])\n","n_classes = len(le.classes_)\n","\n","# if local:\n","#     with open('label_encoder.pkl', 'wb') as f:\n","#         pickle.dump(le, f)"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:34.096662Z","iopub.status.busy":"2024-12-02T01:34:34.096102Z","iopub.status.idle":"2024-12-02T01:34:34.118326Z","shell.execute_reply":"2024-12-02T01:34:34.117336Z","shell.execute_reply.started":"2024-12-02T01:34:34.096623Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(4) Created DataLoaders\n"]}],"source":["# Define custom dataset, which tokenizes question and answer together\n","# If the token length is greater than max_len, truncate the question (never the answer)\n","\n","class MisconceptionDataset(Dataset):\n","    def __init__(self, questions, answers, labels, tokenizer, max_len=256):\n","        self.questions = questions\n","        self.answers = answers\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.questions)\n","\n","    def __getitem__(self, idx):\n","        question = str(self.questions[idx])\n","        answer = str(self.answers[idx])\n","        encoding = self.tokenizer.encode_plus(\n","            question,\n","            answer,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            padding='max_length',\n","            truncation='only_first',\n","            return_attention_mask=True,\n","            return_tensors='pt'\n","        )\n","\n","        return {\n","            'input_ids': encoding['input_ids'].flatten(),\n","            'attention_mask': encoding['attention_mask'].flatten(),\n","            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n","        }\n","\n","\n","# Create datasets and dataloaders\n","\n","train_dataset = MisconceptionDataset(\n","    questions=train['QuestionText'].to_numpy(),\n","    answers=train['AnswerText'].to_numpy(),\n","    labels=train_labels,\n","    tokenizer=tokenizer\n",")\n","\n","val_dataset = MisconceptionDataset(\n","    questions=valid['QuestionText'].to_numpy(),\n","    answers=valid['AnswerText'].to_numpy(),\n","    labels=val_labels,\n","    tokenizer=tokenizer\n",")\n","\n","if local:\n","    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","else:\n","    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True, prefetch_factor=2)\n","    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True, prefetch_factor=2)\n","\n","if log: print(\"(4) Created DataLoaders\")"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>QuestionId</th>\n","      <th>ConstructId</th>\n","      <th>ConstructName</th>\n","      <th>SubjectId</th>\n","      <th>SubjectName</th>\n","      <th>CorrectAnswer</th>\n","      <th>QuestionText</th>\n","      <th>AnswerText</th>\n","      <th>AnswerOption</th>\n","      <th>MisconceptionId</th>\n","      <th>MisconceptionName</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2948</th>\n","      <td>1079</td>\n","      <td>479</td>\n","      <td>Calculate the square root of a number</td>\n","      <td>246</td>\n","      <td>Square Roots, Cube Roots, etc</td>\n","      <td>D</td>\n","      <td>What is the square root of sixteen?</td>\n","      <td>\\( 32 \\)</td>\n","      <td>B</td>\n","      <td>2017.0</td>\n","      <td>Mixes up square rooting and multiplying by 2 or doubling</td>\n","    </tr>\n","    <tr>\n","      <th>3900</th>\n","      <td>162</td>\n","      <td>2760</td>\n","      <td>Calculate the median as an average from an even numbered list of data</td>\n","      <td>102</td>\n","      <td>Averages (mean, median, mode) from a List of Data</td>\n","      <td>A</td>\n","      <td>What is the median of the following numbers?\\n\\[\\n3,5,6,18,18,-4\\n\\]</td>\n","      <td>\\( 6 \\)</td>\n","      <td>C</td>\n","      <td>2426.0</td>\n","      <td>When finding the median from a even dataset does not understand we must find the midpoint of the two values in the middle</td>\n","    </tr>\n","    <tr>\n","      <th>2379</th>\n","      <td>510</td>\n","      <td>1961</td>\n","      <td>Identify questions involving a 2D right-angled triangle that require the use of the Tangent (tan) ratio</td>\n","      <td>279</td>\n","      <td>Right-angled Triangles (SOHCAHTOA)</td>\n","      <td>C</td>\n","      <td>Which ratio would you use to find the value of \\( p \\) ? ![A right-angled triangle with the angle labelled 32 degrees, the side adjacent to this is 6cm and the side opposite is p.]()</td>\n","      <td>Cos</td>\n","      <td>B</td>\n","      <td>809.0</td>\n","      <td>Uses cos when tan is required</td>\n","    </tr>\n","    <tr>\n","      <th>6256</th>\n","      <td>649</td>\n","      <td>311</td>\n","      <td>Multiply a decimal by an integer</td>\n","      <td>224</td>\n","      <td>Multiplying and Dividing with Decimals</td>\n","      <td>B</td>\n","      <td>Tom and Katie are discussing multiplying decimals.\\n\\nTom says \\( 5 \\times 3.9=3 \\times 5.9 \\)\\n\\nKatie says \\( 5 \\times 3.9=3.9 \\times 5 \\)\\n\\nWho is correct?</td>\n","      <td>Neither is correct</td>\n","      <td>D</td>\n","      <td>638.0</td>\n","      <td>Believes multiplication is not commutative</td>\n","    </tr>\n","    <tr>\n","      <th>912</th>\n","      <td>912</td>\n","      <td>100</td>\n","      <td>Recognise and use efficient strategies for mental subtraction</td>\n","      <td>203</td>\n","      <td>Mental Addition and Subtraction</td>\n","      <td>B</td>\n","      <td>Nick wants to subtract \\( 199 \\) from a number.\\nWhich one of the following methods would give him the correct answer?</td>\n","      <td>\\( +200 \\) then \\( +1 \\)</td>\n","      <td>A</td>\n","      <td>1338.0</td>\n","      <td>Does not understand the effect of consecutive operations</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      QuestionId  ConstructId  \\\n","2948        1079          479   \n","3900         162         2760   \n","2379         510         1961   \n","6256         649          311   \n","912          912          100   \n","\n","                                                                                                ConstructName  \\\n","2948                                                                    Calculate the square root of a number   \n","3900                                    Calculate the median as an average from an even numbered list of data   \n","2379  Identify questions involving a 2D right-angled triangle that require the use of the Tangent (tan) ratio   \n","6256                                                                         Multiply a decimal by an integer   \n","912                                             Recognise and use efficient strategies for mental subtraction   \n","\n","      SubjectId                                        SubjectName  \\\n","2948        246                      Square Roots, Cube Roots, etc   \n","3900        102  Averages (mean, median, mode) from a List of Data   \n","2379        279                 Right-angled Triangles (SOHCAHTOA)   \n","6256        224             Multiplying and Dividing with Decimals   \n","912         203                    Mental Addition and Subtraction   \n","\n","     CorrectAnswer  \\\n","2948             D   \n","3900             A   \n","2379             C   \n","6256             B   \n","912              B   \n","\n","                                                                                                                                                                                QuestionText  \\\n","2948                                                                                                                                                     What is the square root of sixteen?   \n","3900                                                                                                                    What is the median of the following numbers?\\n\\[\\n3,5,6,18,18,-4\\n\\]   \n","2379  Which ratio would you use to find the value of \\( p \\) ? ![A right-angled triangle with the angle labelled 32 degrees, the side adjacent to this is 6cm and the side opposite is p.]()   \n","6256                         Tom and Katie are discussing multiplying decimals.\\n\\nTom says \\( 5 \\times 3.9=3 \\times 5.9 \\)\\n\\nKatie says \\( 5 \\times 3.9=3.9 \\times 5 \\)\\n\\nWho is correct?   \n","912                                                                   Nick wants to subtract \\( 199 \\) from a number.\\nWhich one of the following methods would give him the correct answer?   \n","\n","                    AnswerText AnswerOption  MisconceptionId  \\\n","2948                  \\( 32 \\)            B           2017.0   \n","3900                   \\( 6 \\)            C           2426.0   \n","2379                       Cos            B            809.0   \n","6256        Neither is correct            D            638.0   \n","912   \\( +200 \\) then \\( +1 \\)            A           1338.0   \n","\n","                                                                                                              MisconceptionName  \n","2948                                                                   Mixes up square rooting and multiplying by 2 or doubling  \n","3900  When finding the median from a even dataset does not understand we must find the midpoint of the two values in the middle  \n","2379                                                                                              Uses cos when tan is required  \n","6256                                                                                 Believes multiplication is not commutative  \n","912                                                                    Does not understand the effect of consecutive operations  "]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(A) Calculating token lengths for each question-answer pair...\n","(B) Token lengths calculated.\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/w3/z8qntdcx62v2qmj6z9fwfhrh0000gp/T/ipykernel_96474/2267279171.py:14: FutureWarning: \n","\n","`shade` is now deprecated in favor of `fill`; setting `fill=True`.\n","This will become an error in seaborn v0.14.0; please update your code.\n","\n","  sns.kdeplot(\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 1000x600 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def get_token_length(question, answer, tokenizer):\n","    tokens = tokenizer.encode(question, answer, add_special_tokens=True)\n","    return len(tokens)\n","\n","# Apply the function to compute token lengths\n","print(\"(A) Calculating token lengths for each question-answer pair...\")\n","train_melted['TokenLength'] = train_melted.apply(\n","    lambda x: get_token_length(x['QuestionText'], x['AnswerText'], tokenizer), axis=1\n",")\n","print(\"(B) Token lengths calculated.\")\n","\n","# Plotting the KDE\n","plt.figure(figsize=(10, 6))\n","sns.kdeplot(\n","    data=train_melted,\n","    x='TokenLength',\n","    shade=True,\n","    color='skyblue',\n","    linewidth=2\n",")\n","plt.title('KDE of Token Lengths for Question + Answer Pairs')\n","plt.xlabel('Token Length')\n","plt.ylabel('Density')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Train model"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["def calculate_map25(predictions, labels, k=25):\n","    \"\"\"\n","    Calculate MAP@25 for a batch of predictions\n","    predictions: tensor of shape (batch_size, num_classes) with model outputs\n","    labels: tensor of shape (batch_size) with true labels\n","    \"\"\"\n","    batch_size = predictions.size(0)\n","    if batch_size == 0:\n","        return 0.0\n","    \n","    # Get top k predictions\n","    _, pred_indices = predictions.topk(k)\n","    pred_indices = pred_indices.cpu().numpy()\n","    labels = labels.cpu().numpy()\n","    \n","    # Calculate AP for each sample\n","    aps = []\n","    for i in range(batch_size):\n","        ap = 0\n","        hits = 0\n","        for j in range(min(k, len(pred_indices[i]))):\n","            if pred_indices[i][j] == labels[i]:\n","                hits += 1\n","                ap += hits / (j + 1)\n","                break  # Since there's only one correct label per observation\n","        aps.append(ap)\n","    \n","    return np.mean(aps)"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:34:34.119721Z","iopub.status.busy":"2024-12-02T01:34:34.119355Z","iopub.status.idle":"2024-12-02T01:37:29.551904Z","shell.execute_reply":"2024-12-02T01:37:29.550777Z","shell.execute_reply.started":"2024-12-02T01:34:34.119667Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(5) Begin training\n","Epoch 1/3\n"]},{"name":"stderr","output_type":"stream","text":["Training:  12%|        | 5/43 [02:37<19:54, 31.42s/it]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[43], line 81\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 81\u001b[0m     train_acc, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m accuracy \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     84\u001b[0m     val_acc, val_loss, val_map \u001b[38;5;241m=\u001b[39m eval_model(model, val_loader, criterion, device)\n","Cell \u001b[0;32mIn[43], line 30\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     28\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     32\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","Cell \u001b[0;32mIn[37], line 16\u001b[0m, in \u001b[0;36mBERTClassifier.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[0;32m---> 16\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# [CLS] token\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    686\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    692\u001b[0m         output_attentions,\n\u001b[1;32m    693\u001b[0m     )\n\u001b[1;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n","File \u001b[0;32m~/Downloads/idsn544/math-misconceptions/.venv/lib/python3.11/site-packages/transformers/models/bert/modeling_bert.py:440\u001b[0m, in \u001b[0;36mBertSdpaSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# We dispatch to SDPA's Flash Attention or Efficient kernels via this `is_causal` if statement instead of an inline conditional assignment\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# in SDPA to support both torch.compile's dynamic shapes and full graph options. An inline conditional prevents dynamic shapes from compiling.\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# The tgt_len > 1 is necessary to match with AttentionMaskConverter.to_causal_4d that does not create\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# a causal mask in case tgt_len == 1.\u001b[39;00m\n\u001b[1;32m    436\u001b[0m is_causal \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cross_attention \u001b[38;5;129;01mand\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tgt_len \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    438\u001b[0m )\n\u001b[0;32m--> 440\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    450\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["if local: \n","    model_path = '../models/bert-30-20241203.pkl'\n","    if log: print(\"(5) Loading model\")\n","    with open(model_path, 'rb') as f:\n","        model = pickle.load(f)\n","    if log: print(\"(6) Finished loading model\")\n","    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","else:\n","    # Initialize the model\n","    model = BERTClassifier(n_classes=n_classes)\n","    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","    # Define optimizer and loss function\n","    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    # Training loop\n","    from tqdm import tqdm\n","    def train_epoch(model, data_loader, optimizer, criterion, device):\n","        model = model.train()\n","        losses = []\n","        correct_predictions = 0\n","\n","        for batch in tqdm(data_loader, desc=\"Training\"):\n","            input_ids = batch['input_ids'].to(device)\n","            attention_mask = batch['attention_mask'].to(device)\n","            labels = batch['labels'].to(device)\n","\n","            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","            _, preds = torch.max(outputs, dim=1)\n","            loss = criterion(outputs, labels)\n","\n","            correct_predictions += torch.sum(preds == labels)\n","            losses.append(loss.item())\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","        return correct_predictions.double() / len(data_loader.dataset), np.mean(losses)\n","\n","    # Validation loop\n","\n","    def eval_model(model, data_loader, criterion, device):\n","        model = model.eval()\n","        losses = []\n","        correct_predictions = 0\n","        map_scores = []\n","\n","        with torch.no_grad():\n","            for batch in tqdm(data_loader, desc=\"Validation\"):\n","                input_ids = batch['input_ids'].to(device)\n","                attention_mask = batch['attention_mask'].to(device)\n","                labels = batch['labels'].to(device)\n","\n","                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","                _, preds = torch.max(outputs, dim=1)\n","                loss = criterion(outputs, labels)\n","\n","                # Calculate standard metrics\n","                correct_predictions += torch.sum(preds == labels)\n","                losses.append(loss.item())\n","                \n","                # Calculate MAP@25\n","                map_score = calculate_map25(outputs, labels)\n","                map_scores.append(map_score)\n","\n","        accuracy = correct_predictions.double() / len(data_loader.dataset)\n","        avg_loss = np.mean(losses)\n","        avg_map = np.mean(map_scores)\n","\n","        return accuracy, avg_loss, avg_map\n","    \n","    if log: print(\"(5) Begin training\")\n","    EPOCHS = 3\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","    # Training loop\n","    for epoch in range(EPOCHS):\n","        print(f'Epoch {epoch + 1}/{EPOCHS}')\n","        train_acc, train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n","        print(f'Train loss {train_loss:.4f} accuracy {train_acc:.4f}')\n","\n","        val_acc, val_loss, val_map = eval_model(model, val_loader, criterion, device)\n","        print(f'Val   loss {val_loss:.4f} accuracy {val_acc:.4f} MAP@25 {val_map:.4f}')\n","        print('-' * 10)\n","    \n","    if log: print(\"(6) Finish training\")"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'EPOCHS' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/model-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mEPOCHS\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-20241203.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(model_filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      3\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(model, f)\n","\u001b[0;31mNameError\u001b[0m: name 'EPOCHS' is not defined"]}],"source":["# model_filename = f\"../models/model-{EPOCHS}-20241203.pkl\"\n","# with open(model_filename, 'wb') as f:\n","#     pickle.dump(model, f)"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>QuestionId</th>\n","      <th>ConstructId</th>\n","      <th>ConstructName</th>\n","      <th>SubjectId</th>\n","      <th>SubjectName</th>\n","      <th>CorrectAnswer</th>\n","      <th>QuestionText</th>\n","      <th>AnswerAText</th>\n","      <th>AnswerBText</th>\n","      <th>AnswerCText</th>\n","      <th>AnswerDText</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1869</td>\n","      <td>856</td>\n","      <td>Use the order of operations to carry out calculations involving powers</td>\n","      <td>33</td>\n","      <td>BIDMAS</td>\n","      <td>A</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets need to go to make the answer equal \\( 13 \\) ?</td>\n","      <td>\\( 3 \\times(2+4)-5 \\)</td>\n","      <td>\\( 3 \\times 2+(4-5) \\)</td>\n","      <td>\\( 3 \\times(2+4-5) \\)</td>\n","      <td>Does not need brackets</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1870</td>\n","      <td>1612</td>\n","      <td>Simplify an algebraic fraction by factorising the numerator</td>\n","      <td>1077</td>\n","      <td>Simplifying Algebraic Fractions</td>\n","      <td>D</td>\n","      <td>Simplify the following, if possible: \\( \\frac{m^{2}+2 m-3}{m-3} \\)</td>\n","      <td>\\( m+1 \\)</td>\n","      <td>\\( m+2 \\)</td>\n","      <td>\\( m-1 \\)</td>\n","      <td>Does not simplify</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1871</td>\n","      <td>2774</td>\n","      <td>Calculate the range from a list of data</td>\n","      <td>339</td>\n","      <td>Range and Interquartile Range from a List of Data</td>\n","      <td>B</td>\n","      <td>Tom and Katie are discussing the \\( 5 \\) plants with these heights:\\n\\( 24 \\mathrm{~cm}, 17 \\mathrm{~cm}, 42 \\mathrm{~cm}, 26 \\mathrm{~cm}, 13 \\mathrm{~cm} \\)\\nTom says if all the plants were cut in half, the range wouldn't change.\\nKatie says if all the plants grew by \\( 3 \\mathrm{~cm} \\) each, the range wouldn't change.\\nWho do you agree with?</td>\n","      <td>Only\\nTom</td>\n","      <td>Only\\nKatie</td>\n","      <td>Both Tom and Katie</td>\n","      <td>Neither is correct</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   QuestionId  ConstructId  \\\n","0        1869          856   \n","1        1870         1612   \n","2        1871         2774   \n","\n","                                                            ConstructName  \\\n","0  Use the order of operations to carry out calculations involving powers   \n","1             Simplify an algebraic fraction by factorising the numerator   \n","2                                 Calculate the range from a list of data   \n","\n","   SubjectId                                        SubjectName CorrectAnswer  \\\n","0         33                                             BIDMAS             A   \n","1       1077                    Simplifying Algebraic Fractions             D   \n","2        339  Range and Interquartile Range from a List of Data             B   \n","\n","                                                                                                                                                                                                                                                                                                                                                  QuestionText  \\\n","0                                                                                                                                                                                                                                                                 \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets need to go to make the answer equal \\( 13 \\) ?   \n","1                                                                                                                                                                                                                                                                                           Simplify the following, if possible: \\( \\frac{m^{2}+2 m-3}{m-3} \\)   \n","2  Tom and Katie are discussing the \\( 5 \\) plants with these heights:\\n\\( 24 \\mathrm{~cm}, 17 \\mathrm{~cm}, 42 \\mathrm{~cm}, 26 \\mathrm{~cm}, 13 \\mathrm{~cm} \\)\\nTom says if all the plants were cut in half, the range wouldn't change.\\nKatie says if all the plants grew by \\( 3 \\mathrm{~cm} \\) each, the range wouldn't change.\\nWho do you agree with?   \n","\n","             AnswerAText             AnswerBText            AnswerCText  \\\n","0  \\( 3 \\times(2+4)-5 \\)  \\( 3 \\times 2+(4-5) \\)  \\( 3 \\times(2+4-5) \\)   \n","1              \\( m+1 \\)               \\( m+2 \\)              \\( m-1 \\)   \n","2              Only\\nTom             Only\\nKatie     Both Tom and Katie   \n","\n","              AnswerDText  \n","0  Does not need brackets  \n","1       Does not simplify  \n","2      Neither is correct  "]},"execution_count":108,"metadata":{},"output_type":"execute_result"}],"source":["test.head()"]},{"cell_type":"markdown","metadata":{},"source":["## Predict"]},{"cell_type":"code","execution_count":109,"metadata":{"execution":{"iopub.execute_input":"2024-12-02T01:40:05.430706Z","iopub.status.busy":"2024-12-02T01:40:05.430362Z","iopub.status.idle":"2024-12-02T01:40:05.595753Z","shell.execute_reply":"2024-12-02T01:40:05.594707Z","shell.execute_reply.started":"2024-12-02T01:40:05.430661Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["(7) Melt test set\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>QuestionId</th>\n","      <th>QuestionText</th>\n","      <th>CorrectAnswer</th>\n","      <th>AnswerOption</th>\n","      <th>AnswerText</th>\n","      <th>QA_Id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1870</td>\n","      <td>Simplify the following, if possible: \\( \\frac{m^{2}+2 m-3}{m-3} \\)</td>\n","      <td>D</td>\n","      <td>A</td>\n","      <td>\\( m+1 \\)</td>\n","      <td>1870_A</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1871</td>\n","      <td>Tom and Katie are discussing the \\( 5 \\) plants with these heights:\\n\\( 24 \\mathrm{~cm}, 17 \\mathrm{~cm}, 42 \\mathrm{~cm}, 26 \\mathrm{~cm}, 13 \\mathrm{~cm} \\)\\nTom says if all the plants were cut in half, the range wouldn't change.\\nKatie says if all the plants grew by \\( 3 \\mathrm{~cm} \\) each, the range wouldn't change.\\nWho do you agree with?</td>\n","      <td>B</td>\n","      <td>A</td>\n","      <td>Only\\nTom</td>\n","      <td>1871_A</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1869</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets need to go to make the answer equal \\( 13 \\) ?</td>\n","      <td>A</td>\n","      <td>B</td>\n","      <td>\\( 3 \\times 2+(4-5) \\)</td>\n","      <td>1869_B</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1870</td>\n","      <td>Simplify the following, if possible: \\( \\frac{m^{2}+2 m-3}{m-3} \\)</td>\n","      <td>D</td>\n","      <td>B</td>\n","      <td>\\( m+2 \\)</td>\n","      <td>1870_B</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1869</td>\n","      <td>\\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets need to go to make the answer equal \\( 13 \\) ?</td>\n","      <td>A</td>\n","      <td>C</td>\n","      <td>\\( 3 \\times(2+4-5) \\)</td>\n","      <td>1869_C</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   QuestionId  \\\n","1        1870   \n","2        1871   \n","3        1869   \n","4        1870   \n","6        1869   \n","\n","                                                                                                                                                                                                                                                                                                                                                  QuestionText  \\\n","1                                                                                                                                                                                                                                                                                           Simplify the following, if possible: \\( \\frac{m^{2}+2 m-3}{m-3} \\)   \n","2  Tom and Katie are discussing the \\( 5 \\) plants with these heights:\\n\\( 24 \\mathrm{~cm}, 17 \\mathrm{~cm}, 42 \\mathrm{~cm}, 26 \\mathrm{~cm}, 13 \\mathrm{~cm} \\)\\nTom says if all the plants were cut in half, the range wouldn't change.\\nKatie says if all the plants grew by \\( 3 \\mathrm{~cm} \\) each, the range wouldn't change.\\nWho do you agree with?   \n","3                                                                                                                                                                                                                                                                 \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets need to go to make the answer equal \\( 13 \\) ?   \n","4                                                                                                                                                                                                                                                                                           Simplify the following, if possible: \\( \\frac{m^{2}+2 m-3}{m-3} \\)   \n","6                                                                                                                                                                                                                                                                 \\[\\n3 \\times 2+4-5\\n\\]\\nWhere do the brackets need to go to make the answer equal \\( 13 \\) ?   \n","\n","  CorrectAnswer AnswerOption              AnswerText   QA_Id  \n","1             D            A               \\( m+1 \\)  1870_A  \n","2             B            A               Only\\nTom  1871_A  \n","3             A            B  \\( 3 \\times 2+(4-5) \\)  1869_B  \n","4             D            B               \\( m+2 \\)  1870_B  \n","6             A            C   \\( 3 \\times(2+4-5) \\)  1869_C  "]},"execution_count":109,"metadata":{},"output_type":"execute_result"}],"source":["if log: print(\"(7) Melt test set\")\n","    \n","# Create a dictionary to map MisconceptionName to MisconceptionId\n","name_to_id = misconceptions.reset_index().set_index('MisconceptionName')['MisconceptionId'].to_dict()\n","\n","# Reshape the test DataFrame to have one row per QuestionId_Answer (A, B, C, D)\n","\n","# Include 'QuestionText' in id_vars to preserve it in the melted DataFrame\n","test_melted = test.melt(\n","    id_vars=['QuestionId', 'QuestionText', 'CorrectAnswer'],\n","    value_vars=['AnswerAText', 'AnswerBText', 'AnswerCText', 'AnswerDText'],\n","    var_name='AnswerOption',\n","    value_name='AnswerText'\n",")\n","\n","# Clean the 'AnswerOption' column to obtain A, B, C, D\n","test_melted['AnswerOption'] = test_melted['AnswerOption'].str.replace('Answer', '').str.replace('Text', '')\n","\n","test_melted['QA_Id'] = test_melted['QuestionId'].astype(str) + '_' + test_melted['AnswerOption']\n","\n","# Drop correct answers\n","test_melted = test_melted[test_melted['CorrectAnswer'] != test_melted['AnswerOption']]\n","\n","test_melted.head()\n"]},{"cell_type":"code","execution_count":110,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(8) Making predictions\n"]},{"name":"stderr","output_type":"stream","text":["Testing: 100%|| 1/1 [00:00<00:00,  1.58it/s]"]},{"name":"stdout","output_type":"stream","text":["(9) Creating submission file\n","Submission file created successfully.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["test_dataset = MisconceptionDataset(\n","    questions=test_melted['QuestionText'].to_numpy(),\n","    answers=test_melted['AnswerText'].to_numpy(),\n","    labels=[0]*len(test_melted), \n","    tokenizer=tokenizer\n",")\n","test_loader = DataLoader(test_dataset, batch_size=16)\n","\n","if log: print(\"(8) Making predictions\")\n","\n","# Make predictions\n","model = model.eval()\n","predictions = []\n","\n","with torch.no_grad():\n","    for batch in tqdm(test_loader, desc=\"Testing\"):\n","        input_ids = batch['input_ids'].to(device)\n","        attention_mask = batch['attention_mask'].to(device)\n","        \n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n","        probs = torch.softmax(outputs, dim=1)\n","        # Get top 25 predictions\n","        topk = probs.topk(25, dim=1)\n","        preds = topk.indices.cpu().numpy()\n","        predictions.extend(preds)\n","\n","# Decode predictions\n","\n","# Inverse transform to get MisconceptionName from class indices\n","predicted_misconceptions = [le.inverse_transform(pred) for pred in predictions]\n","\n","# Map MisconceptionName to MisconceptionId using the name_to_id dictionary\n","predicted_misconception_ids = [\n","    ' '.join(str(name_to_id.get(name, 0)) for name in preds) for preds in predicted_misconceptions\n","]\n","\n","\n","if log: print(\"(9) Creating submission file\")\n","\n","# Create submission DataFrame\n","submission = pd.DataFrame({\n","    'QuestionId_Answer': test_melted['QA_Id'],\n","    'MisconceptionId': predicted_misconception_ids\n","})\n","\n","# Ensure that each 'MisconceptionId' has up to 25 MisconceptionIds\n","submission['MisconceptionId'] = submission['MisconceptionId'].apply(lambda x: ' '.join(x.split()[:25]))\n","\n","# Save to CSV\n","submission.to_csv('submission.csv', index=False)\n","\n","print(\"Submission file created successfully.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":9738540,"sourceId":82695,"sourceType":"competition"},{"modelId":177888,"modelInstanceId":155418,"sourceId":182326,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
